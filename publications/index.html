<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Nikos Kolotouros


  | publications

</title>
<meta name="description" content="This is my personal webpage.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>N</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/publications/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3JSJNQ5JHQ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-3JSJNQ5JHQ');
</script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       Nikos Kolotouros
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/resume/">
                resume
                
              </a>
          </li>
          
          
          
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description">My publications in reversed chronological order.</p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2023</h2>
  <ol class="bibliography"><li><style>
    .teaser {
        position: relative;
        display: inline-block;
    }
    .teaser .teaser-top {
        display: none;
        position: absolute; 
        top: 0;
        left: 0;
    }
    .teaser:hover .teaser-top {
        display: inline;
    }
</style>

<div class="row">
<div id="kolotouros2023dreamhuman_teaser" class="col-sm-2">
    <div class="teaser">
        <img width="100%" src="/assets/img/teasers/dreamhuman.jpg" />
        <img width="100%" src="/assets/img/teasers/dreamhuman.gif" class="teaser-top" />
    </div>
</div>
  <div id="kolotouros2023dreamhuman" class="col-sm-8">
    
      <div class="title">DreamHuman: Animatable 3D Avatars from Text</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Kolotouros, Nikos</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://research.google/people/thiemo-alldieck" target="_blank">Alldieck, Thiemo</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.com/citations?user=8lmzWycAAAAJ&amp;hl=pt-PT" target="_blank">Zanfir, Andrei</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://research.google/people/eduard-gabriel-bazavan" target="_blank">Bazavan, Eduard Gabriel</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://mihaifieraru.github.io/" target="_blank">Fieraru, Mihai</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://research.google/people/CristianSminchisescu/" target="_blank">Sminchisescu, Cristian</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In NeurIPS</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://openreview.net/pdf?id=rheCTpRrxI" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
      <a href="https://dream-human.github.io" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present DreamHuman, a method to generate realistic animatable 3D human avatar models solely from textual descriptions. Recent text-to-3D methods have made considerable strides in generation, but are still lacking in important aspects. Control and often spatial resolution remain limited, existing methods produce fixed rather than animated 3D human models, and anthropometric consistency for complex structures like people remains a challenge. DreamHuman connects large text-to-image synthesis models, neural radiance fields, and statistical human body models in a novel modeling and optimization framework. This makes it possible to generate dynamic 3D human avatars with high-quality textures and learned, instance-specific, surface deformations. We demonstrate that our method is capable to generate a wide variety of animatable, realistic 3D human models from text. Our 3D models have diverse appearance, clothing, skin tones and body shapes, and significantly outperform both generic text-to-3D approaches and previous text-based 3D avatar generators in visual fidelity.
</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kolotouros2023dreamhuman</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DreamHuman: Animatable 3D Avatars from Text}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kolotouros, Nikos and Alldieck, Thiemo and Zanfir, Andrei and Bazavan, Eduard Gabriel and Fieraru, Mihai and Sminchisescu, Cristian}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{NeurIPS}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">website</span> <span class="p">=</span> <span class="s">{https://dream-human.github.io}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://openreview.net/pdf?id=rheCTpRrxI}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{dreamhuman}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><style>
    .teaser {
        position: relative;
        display: inline-block;
    }
    .teaser .teaser-top {
        display: none;
        position: absolute; 
        top: 0;
        left: 0;
    }
    .teaser:hover .teaser-top {
        display: inline;
    }
</style>

<div class="row">
<div id="kolotouros2021prohmr_teaser" class="col-sm-2">
    <div class="teaser">
        <img width="100%" src="/assets/img/teasers/prohmr.png" />
        <img width="100%" src="/assets/img/teasers/prohmr_top.png" class="teaser-top" />
    </div>
</div>
  <div id="kolotouros2021prohmr" class="col-sm-8">
    
      <div class="title">Probabilistic Modeling for Human Mesh Recovery</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Kolotouros, Nikos</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://geopavlakos.github.io" target="_blank">Pavlakos, Georgios</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="http://seas.upenn.edu/~dineshj" target="_blank">Jayaraman, Dinesh</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://cis.upenn.edu/~kostas" target="_blank">Daniilidis, Kostas</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In ICCV</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/2108.11944" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
      
      <a href="https://openaccess.thecvf.com/content/ICCV2021/supplemental/Kolotouros_Probabilistic_Modeling_for_ICCV_2021_supplemental.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Supp</a>
      
    
    
    
      <a href="https://github.com/nkolot/ProHMR" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
      <a href="/projects/prohmr/" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
    
    
      <a href="https://www.rsipvision.com/ComputerVisionNews-2021November/28/" class="btn btn-sm z-depth-0" role="button" target="_blank">Interview</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper focuses on the problem of 3D human reconstruction from 2D evidence. Although this is an inherently ambiguous problem, the majority of recent works avoid the uncertainty modeling and typically regress a single estimate for a given input. In contrast to that, in this work, we propose to embrace the reconstruction ambiguity and we recast the problem as learning a mapping from the input to a distribution of plausible 3D poses. Our approach is based on the normalizing flows model
      and offers a series of advantages. For conventional applications, where a single 3D estimate is required, our formulation allows for efficient mode computation. Using the mode leads to performance that is comparable with the state of the art among deterministic unimodal regression models. Simultaneously, since we have access to the likelihood of each sample, we demonstrate that our model is useful in a series of downstream tasks, where we leverage the probabilistic nature of the prediction
          as a tool for more accurate estimation. These tasks include reconstruction from multiple uncalibrated views, as well as human model fitting, where our model acts as a powerful image-based prior for mesh recovery. Our results validate the importance of probabilistic modeling, and indicate state-of-the-art performance across a variety of settings. Code and models are available at: https://www.nikoskolot.com/projects/prohmr.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kolotouros2021prohmr</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Probabilistic Modeling for Human Mesh Recovery}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kolotouros, Nikos and Pavlakos, Georgios and Jayaraman, Dinesh and Daniilidis, Kostas}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICCV}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">website</span> <span class="p">=</span> <span class="s">{/projects/prohmr/}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/pdf/2108.11944}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/nkolot/ProHMR}</span><span class="p">,</span>
  <span class="na">supp</span> <span class="p">=</span> <span class="s">{https://openaccess.thecvf.com/content/ICCV2021/supplemental/Kolotouros_Probabilistic_Modeling_for_ICCV_2021_supplemental.pdf}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{prohmr}</span><span class="p">,</span>
  <span class="na">interview</span> <span class="p">=</span> <span class="s">{https://www.rsipvision.com/ComputerVisionNews-2021November/28/}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li><style>
    .teaser {
        position: relative;
        display: inline-block;
    }
    .teaser .teaser-top {
        display: none;
        position: absolute; 
        top: 0;
        left: 0;
    }
    .teaser:hover .teaser-top {
        display: inline;
    }
</style>

<div class="row">
<div id="wang2021aves_teaser" class="col-sm-2">
    <div class="teaser">
        <img width="100%" src="/assets/img/teasers/aves.png" />
        <img width="100%" src="/assets/img/teasers/aves.png" class="teaser-top" />
    </div>
</div>
  <div id="wang2021aves" class="col-sm-8">
    
      <div class="title">Birds of a Feather: Capturing Avian Shape Models from Images</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://yufu-wang.github.io/" target="_blank">Wang, Yufu</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kolotouros, Nikos</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://cis.upenn.edu/~kostas" target="_blank">Daniilidis, Kostas</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://www.ocf.berkeley.edu/~badger/" target="_blank">Badger, Marc</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In CVPR</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/2105.09396" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
      
      <a href="https://marcbadger.github.io/avian-mesh/files/3d_birds_singleview-supp.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Supp</a>
      
    
    
    
      <a href="https://github.com/yufu-wang/aves" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
      <a href="https://yufu-wang.github.io/aves/" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Automated capture of animal pose is transforming how we study neuroscience and social behavior. Movements carry important social cues, but current methods are not able to robustly estimate pose and shape of animals, particularly for social animals such as birds, which are often occluded by each other and objects in the environment. To address this problem, we first introduce a model and multi-view optimization approach, which we use to capture the unique shape and pose space
      displayed by live birds. We then introduce a pipeline and experiments for keypoint, mask, pose, and shape regression that recovers accurate avian postures from single views. Finally, we provide extensive multi-view keypoint and mask annotations collected from a group of 15 social birds housed together in an outdoor aviary.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wang2021aves</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Birds of a Feather: Capturing Avian Shape Models from Images}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Yufu and Kolotouros, Nikos and Daniilidis, Kostas and Badger, Marc}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{CVPR}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">website</span> <span class="p">=</span> <span class="s">{https://yufu-wang.github.io/aves/}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/pdf/2105.09396}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/yufu-wang/aves}</span><span class="p">,</span>
  <span class="na">supp</span> <span class="p">=</span> <span class="s">{https://marcbadger.github.io/avian-mesh/files/3d_birds_singleview-supp.pdf}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{aves}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><style>
    .teaser {
        position: relative;
        display: inline-block;
    }
    .teaser .teaser-top {
        display: none;
        position: absolute; 
        top: 0;
        left: 0;
    }
    .teaser:hover .teaser-top {
        display: inline;
    }
</style>

<div class="row">
<div id="badger2020_teaser" class="col-sm-2">
    <div class="teaser">
        <img width="100%" src="/assets/img/teasers/3dbird.png" />
        <img width="100%" src="/assets/img/teasers/3dbird.png" class="teaser-top" />
    </div>
</div>
  <div id="badger2020" class="col-sm-8">
    
      <div class="title">3D Bird Reconstruction: a Dataset, Model, and Shape Recovery from a Single View</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.ocf.berkeley.edu/~badger/" target="_blank">Badger, Marc</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://yufu-wang.github.io/" target="_blank">Wang, Yufu</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://seas.upenn.edu/~adarshm/" target="_blank">Modh, Adarsh</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://twitter.com/alltheperkes" target="_blank">Perkes, Ammon</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kolotouros, Nikos</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="http://pfrommer.us/" target="_blank">Pfrommer, Bernd</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Schmidt, Marc,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://cis.upenn.edu/~kostas" target="_blank">Daniilidis, Kostas</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In ECCV</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/abs/2008.06133" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
      
      <a href="https://marcbadger.github.io/avian-mesh/files/3d_birds_singleview-supp.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Supp</a>
      
    
    
    
      <a href="https://github.com/marcbadger/avian-mesh" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
      <a href="https://marcbadger.github.io/avian-mesh/" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Automated capture of animal pose is transforming how we study neuroscience and social behavior. Movements carry important social cues, but current methods are not able to robustly estimate pose and shape of animals, particularly for social animals such as birds, which are often occluded by each other and objects in the environment. To address this problem, we first introduce a model and multi-view optimization approach, which we use to capture the unique shape and pose space
      displayed by live birds. We then introduce a pipeline and experiments for keypoint, mask, pose, and shape regression that recovers accurate avian postures from single views. Finally, we provide extensive multi-view keypoint and mask annotations collected from a group of 15 social birds housed together in an outdoor aviary.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">badger2020</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{3D} Bird Reconstruction: a Dataset, Model, and Shape Recovery from a Single View}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Badger, Marc and Wang, Yufu and Modh, Adarsh and Perkes, Ammon and Kolotouros, Nikos and Pfrommer, Bernd and Schmidt, Marc and Daniilidis, Kostas}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ECCV}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">website</span> <span class="p">=</span> <span class="s">{https://marcbadger.github.io/avian-mesh/}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2008.06133}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/marcbadger/avian-mesh}</span><span class="p">,</span>
  <span class="na">supp</span> <span class="p">=</span> <span class="s">{https://marcbadger.github.io/avian-mesh/files/3d_birds_singleview-supp.pdf}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{3dbird}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li><style>
    .teaser {
        position: relative;
        display: inline-block;
    }
    .teaser .teaser-top {
        display: none;
        position: absolute; 
        top: 0;
        left: 0;
    }
    .teaser:hover .teaser-top {
        display: inline;
    }
</style>

<div class="row">
<div id="jiang2020multiperson_teaser" class="col-sm-2">
    <div class="teaser">
        <img width="100%" src="/assets/img/teasers/multiperson.png" />
        <img width="100%" src="/assets/img/teasers/multiperson_top.gif" class="teaser-top" />
    </div>
</div>
  <div id="jiang2020multiperson" class="col-sm-8">
    
      <div class="title">Coherent Reconstruction of Multiple Humans from A Single Image</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://jiangwenpl.github.io/" target="_blank">Jiang, Wen*</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kolotouros, Nikos*</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://geopavlakos.github.io" target="_blank">Pavlakos, Georgios</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="http://xzhou.me/" target="_blank">Zhou, Xiaowei</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://cis.upenn.edu/~kostas" target="_blank">Daniilidis, Kostas</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In CVPR</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/2006.08586.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
      
      <a href="https://jiangwenpl.github.io/multiperson/files/multiperson-supp.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Supp</a>
      
    
    
    
      <a href="https://github.com/JiangWenPL/multiperson" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
      <a href="https://jiangwenpl.github.io/multiperson/" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this work, we address the problem of multi-person 3D pose estimation from a single image. A typical regression approach in the top-down setting of this problem would first detect all humans and then reconstruct each one of them independently. However, this type of predic- tion suffers from incoherent results, e.g., interpenetration and inconsistent depth ordering between the people in the scene. Our goal is to train a single network that learns to avoid these problems and
      generate a coherent 3D reconstruction of all the humans in the scene. To this end, a key design choice is the incorporation of the SMPL parametric body model in our top-down framework, which enables the use of two novel losses. First, a distance field-based collision loss penalizes interpenetration among the reconstructed people. Second, a depth ordering-aware loss reasons about occlusions and promotes a depth ordering of people that leads to a rendering which is consistent with the
          annotated instance segmentation. This provides depth supervision signals to the network, even if the image has no explicit 3D annotations. The experiments show that our approach outperforms previous methods on standard 3D pose benchmarks, while our proposed losses en- able more coherent reconstruction in natural images.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">jiang2020multiperson</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Coherent Reconstruction of Multiple Humans from A Single Image}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jiang, Wen* and Kolotouros, Nikos* and Pavlakos, Georgios and Zhou, Xiaowei and Daniilidis, Kostas}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{CVPR}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">website</span> <span class="p">=</span> <span class="s">{https://jiangwenpl.github.io/multiperson/}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/pdf/2006.08586.pdf}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/JiangWenPL/multiperson}</span><span class="p">,</span>
  <span class="na">supp</span> <span class="p">=</span> <span class="s">{https://jiangwenpl.github.io/multiperson/files/multiperson-supp.pdf}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{multiperson}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li><style>
    .teaser {
        position: relative;
        display: inline-block;
    }
    .teaser .teaser-top {
        display: none;
        position: absolute; 
        top: 0;
        left: 0;
    }
    .teaser:hover .teaser-top {
        display: inline;
    }
</style>

<div class="row">
<div id="kolotouros2019spin_teaser" class="col-sm-2">
    <div class="teaser">
        <img width="100%" src="/assets/img/teasers/spin.png" />
        <img width="100%" src="/assets/img/teasers/spin_top.gif" class="teaser-top" />
    </div>
</div>
  <div id="kolotouros2019spin" class="col-sm-8">
    
      <div class="title">Learning to Reconstruct 3D Human Pose and Shape via Model-fitting in the Loop</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Kolotouros, Nikos*</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://geopavlakos.github.io" target="_blank">Pavlakos, Georgios*</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://ps.is.mpg.de/~black" target="_blank">Black, Michael J.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://cis.upenn.edu/~kostas" target="_blank">Daniilidis, Kostas</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In ICCV</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/abs/1909.12828" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
      
      <a href="https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Kolotouros_Learning_to_Reconstruct_ICCV_2019_supplemental.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Supp</a>
      
    
    
    
      <a href="https://github.com/nkolot/SPIN" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
      <a href="/projects/spin/" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Model-based human pose estimation is currently approached through two different paradigms. Optimization-based methods fit a parametric body model to 2D observations in an iterative manner, leading to accurate image-model alignments, but are often slow and sensitive to the initialization. In contrast, regression-based methods, that use a deep network to directly estimate the model parameters from pixels, tend to provide reasonable, but not pixel accurate, results while requiring
      huge amounts of supervision. In this work, instead of investigating which approach is better, our key insight is that the two paradigms can form a strong collaboration. A reasonable, directly regressed estimate from the network can initialize the iterative optimization making the fitting faster and more accurate. Similarly, a pixel accurate fit from iterative optimization can act as strong supervision for the network. This is the core of our proposed approach SPIN (SMPL oPtimization IN the
              loop). The deep network initializes an iterative optimization routine that fits the body model to 2D joints within the training loop, and the fitted estimate is subsequently used to supervise the network. Our approach is self-improving by nature, since better network estimates can lead the optimization to better solutions, while more accurate optimization fits provide better supervision for the network. We demonstrate the effectiveness of our approach in different settings, where
          3D ground truth is scarce, or not available, and we consistently outperform the state-of-the-art model-based pose estimation approaches by significant margins.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kolotouros2019spin</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning to Reconstruct 3D Human Pose and Shape via Model-fitting in the Loop}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kolotouros, Nikos* and Pavlakos, Georgios* and Black, Michael J. and Daniilidis, Kostas}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICCV}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">website</span> <span class="p">=</span> <span class="s">{/projects/spin/}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/1909.12828}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/nkolot/SPIN}</span><span class="p">,</span>
  <span class="na">supp</span> <span class="p">=</span> <span class="s">{https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Kolotouros_Learning_to_Reconstruct_ICCV_2019_supplemental.pdf}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{spin}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li><style>
    .teaser {
        position: relative;
        display: inline-block;
    }
    .teaser .teaser-top {
        display: none;
        position: absolute; 
        top: 0;
        left: 0;
    }
    .teaser:hover .teaser-top {
        display: inline;
    }
</style>

<div class="row">
<div id="pavlakos2019texturepose_teaser" class="col-sm-2">
    <div class="teaser">
        <img width="100%" src="/assets/img/teasers/texturepose.jpeg" />
        <img width="100%" src="/assets/img/teasers/texturepose.jpeg" class="teaser-top" />
    </div>
</div>
  <div id="pavlakos2019texturepose" class="col-sm-8">
    
      <div class="title">TexturePose: Supervising Human Mesh Estimation with Texture Consistency</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://geopavlakos.github.io" target="_blank">Pavlakos, Georgios*</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kolotouros, Nikos*</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://cis.upenn.edu/~kostas" target="_blank">Daniilidis, Kostas</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In ICCV</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/1910.11322.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
      
      <a href="https://geopavlakos.github.io/projects/texturepose/files/texturepose-supp.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Supp</a>
      
    
    
    
      <a href="https://github.com/geopavlakos/TexturePose" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
      <a href="https://geopavlakos.github.io/projects/texturepose" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This work addresses the problem of model-based human pose estimation. Recent approaches have made significant progress towards regressing the parameters of parametric human body models directly from images. Because of the absence of images with 3D shape ground truth, relevant approaches rely on 2D annotations or sophisticated architecture designs. In this work, we advocate that there are more cues we can leverage, which are available for free in natural images, i.e., without
      getting more annotations, or modifying the network architecture. We propose a natural form of supervision, that capitalizes on the appearance constancy of a person among different frames (or viewpoints). This seemingly insignificant and often overlooked cue goes a long way for model-based pose estimation. The parametric model we employ allows us to compute a texture map for each frame. Assuming that the texture of the person does not change dramatically between frames, we can apply a novel
          texture consistency loss, which enforces that each point in the texture map has the same texture value across all frames. Since the texture is transferred in this common texture map space, no camera motion computation is necessary, or even an assumption of smoothness among frames. This makes our proposed supervision applicable in a variety of settings, ranging from monocular video, to multi-view images. We benchmark our approach against strong baselines that require the same or even
          more annotations that we do and we consistently outperform them. Simultaneously, we achieve state-of-the-art results among model-based pose estimation approaches in different benchmarks</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">pavlakos2019texturepose</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Texture{P}ose: Supervising Human Mesh Estimation with Texture Consistency}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pavlakos, Georgios* and Kolotouros, Nikos* and Daniilidis, Kostas}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICCV}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">website</span> <span class="p">=</span> <span class="s">{https://geopavlakos.github.io/projects/texturepose}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/pdf/1910.11322.pdf}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/geopavlakos/TexturePose}</span><span class="p">,</span>
  <span class="na">supp</span> <span class="p">=</span> <span class="s">{https://geopavlakos.github.io/projects/texturepose/files/texturepose-supp.pdf}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{texturepose}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li><style>
    .teaser {
        position: relative;
        display: inline-block;
    }
    .teaser .teaser-top {
        display: none;
        position: absolute; 
        top: 0;
        left: 0;
    }
    .teaser:hover .teaser-top {
        display: inline;
    }
</style>

<div class="row">
<div id="kolotouros2019cmr_teaser" class="col-sm-2">
    <div class="teaser">
        <img width="100%" src="/assets/img/teasers/cmr.jpeg" />
        <img width="100%" src="/assets/img/teasers/cmr_top.gif" class="teaser-top" />
    </div>
</div>
  <div id="kolotouros2019cmr" class="col-sm-8">
    
      <div class="title">Convolutional Mesh Regression for Single-Image Human Shape Reconstruction</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Kolotouros, Nikos</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://geopavlakos.github.io" target="_blank">Pavlakos, Georgios</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://cis.upenn.edu/~kostas" target="_blank">Daniilidis, Kostas</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In CVPR</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="http://arxiv.org/pdf/1905.03244.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
      
      <a href="https://www.seas.upenn.edu/nkolot/projects/cmr/files/cmr-supp.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Supp</a>
      
    
    
    
      <a href="https://github.com/nkolot/GraphCMR/" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
      <a href="/projects/cmr/" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper addresses the problem of 3D human pose and shape estimation from a single image. Previous approaches consider a parametric model of the human body, SMPL, and attempt to regress the model parameters that give rise to a mesh consistent with image evidence. This parameter regression has been a very challenging task, with model-based approaches underperforming compared to nonparametric solutions in terms of pose estimation. In our work, we propose to relax this heavy
      reliance on the models parameter space. We still retain the topology of the SMPL template mesh, but instead of predicting model parameters, we directly regress the 3D location of the mesh vertices. This is a heavy task for a typical network, but our key insight is that the regression becomes significantly easier using a Graph-CNN. This architecture allows us to explicitly encode the template mesh structure within the network and leverage the spatial locality the mesh has to offer.
          Image-based features are attached to the mesh vertices and the Graph-CNN is responsible to process them on the mesh structure, while the regression target for each vertex is its 3D location. Having recovered the complete 3D geometry of the mesh, if we still require a specific model parametrization, this can be reliably regressed from the vertices locations. We demonstrate the flexibility and the effectiveness of our proposed graph-based mesh regression by attaching different types of
          features on the mesh vertices. In all cases, we outperform the comparable baselines relying on model parameter regression, while we also achieve state-of-the-art results among model-based pose estimation approaches.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kolotouros2019cmr</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kolotouros, Nikos and Pavlakos, Georgios and Daniilidis, Kostas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Convolutional Mesh Regression for Single-Image Human Shape Reconstruction}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{CVPR}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">website</span> <span class="p">=</span> <span class="s">{/projects/cmr/}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{http://arxiv.org/pdf/1905.03244.pdf}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/nkolot/GraphCMR/}</span><span class="p">,</span>
  <span class="na">supp</span> <span class="p">=</span> <span class="s">{https://www.seas.upenn.edu/~nkolot/projects/cmr/files/cmr-supp.pdf}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{cmr}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li></ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2023 Nikos  Kolotouros.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.

    
    
    Last updated: December 19, 2023.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
